{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"driving_log.csv\", names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>reverse</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/data...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/data...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/data...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/data...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/data...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              center  \\\n",
       "0  /home/shiryezzat/AI/deep_learning_project/data...   \n",
       "1  /home/shiryezzat/AI/deep_learning_project/data...   \n",
       "2  /home/shiryezzat/AI/deep_learning_project/data...   \n",
       "3  /home/shiryezzat/AI/deep_learning_project/data...   \n",
       "4  /home/shiryezzat/AI/deep_learning_project/data...   \n",
       "\n",
       "                                                left  \\\n",
       "0   /home/shiryezzat/AI/deep_learning_project/dat...   \n",
       "1   /home/shiryezzat/AI/deep_learning_project/dat...   \n",
       "2   /home/shiryezzat/AI/deep_learning_project/dat...   \n",
       "3   /home/shiryezzat/AI/deep_learning_project/dat...   \n",
       "4   /home/shiryezzat/AI/deep_learning_project/dat...   \n",
       "\n",
       "                                               right  steering  throttle  \\\n",
       "0   /home/shiryezzat/AI/deep_learning_project/dat...       0.0       0.0   \n",
       "1   /home/shiryezzat/AI/deep_learning_project/dat...       0.0       0.0   \n",
       "2   /home/shiryezzat/AI/deep_learning_project/dat...       0.0       0.0   \n",
       "3   /home/shiryezzat/AI/deep_learning_project/dat...       0.0       0.0   \n",
       "4   /home/shiryezzat/AI/deep_learning_project/dat...       0.0       0.0   \n",
       "\n",
       "   reverse     speed  \n",
       "0        0  0.000079  \n",
       "1        0  0.000079  \n",
       "2        0  0.000080  \n",
       "3        0  0.000078  \n",
       "4        0  0.000080  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Define a function to load and replace the paths with images\n",
    "def load_image(row):\n",
    "    image_path = row['center']\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image at path {image_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "data['center'] = data.apply(load_image, axis=1)\n",
    "\n",
    "\n",
    "#import cv2\n",
    "#x = data[[\"center\",\"left\", \"right\"]].values\n",
    "\n",
    "#for i in range(907):\n",
    "#  x[i][0]=cv2.imread(x[i][0])\n",
    "#  x[i][1]=cv2.imread(x[i][1])\n",
    "#  x[i][2]=cv2.imread(x[i][2])\n",
    "\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>reverse</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PIL.JpegImagePlugin.JpegImageFile image mode=...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>/home/shiryezzat/AI/deep_learning_project/dat...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              center  \\\n",
       "0  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "1  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "2  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "3  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "4  <PIL.JpegImagePlugin.JpegImageFile image mode=...   \n",
       "\n",
       "                                                left  \\\n",
       "0   /home/shiryezzat/AI/deep_learning_project/dat...   \n",
       "1   /home/shiryezzat/AI/deep_learning_project/dat...   \n",
       "2   /home/shiryezzat/AI/deep_learning_project/dat...   \n",
       "3   /home/shiryezzat/AI/deep_learning_project/dat...   \n",
       "4   /home/shiryezzat/AI/deep_learning_project/dat...   \n",
       "\n",
       "                                               right  steering  throttle  \\\n",
       "0   /home/shiryezzat/AI/deep_learning_project/dat...       0.0       0.0   \n",
       "1   /home/shiryezzat/AI/deep_learning_project/dat...       0.0       0.0   \n",
       "2   /home/shiryezzat/AI/deep_learning_project/dat...       0.0       0.0   \n",
       "3   /home/shiryezzat/AI/deep_learning_project/dat...       0.0       0.0   \n",
       "4   /home/shiryezzat/AI/deep_learning_project/dat...       0.0       0.0   \n",
       "\n",
       "   reverse     speed  \n",
       "0        0  0.000079  \n",
       "1        0  0.000079  \n",
       "2        0  0.000080  \n",
       "3        0  0.000078  \n",
       "4        0  0.000080  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       ...,\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[[\"steering\",\"throttle\"]].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize_images(image):\n",
    "    img = image.convert('RGB')\n",
    "    img_array = np.array(img)/255.0\n",
    "    return img_array\n",
    "\n",
    "data['center'] = data['center'].apply(normalize_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split #to split out training and testing data \n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(data['center'], y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.stack(x_train, axis=0)\n",
    "x_train = np.transpose(x_train, (0, 3, 1, 2))\n",
    "#X_val = np.stack(X_val, axis=0)\n",
    "#X_val = np.transpose(X_val, (0, 3, 1, 2))\n",
    "x_valid = np.stack(x_valid, axis = 0)\n",
    "x_valid = np.transpose(x_valid, (0, 3, 1, 2))\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "#y_val = np.array(y_val)\n",
    "y_test = np.array(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(725, 3, 160, 320)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiryezzat/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import tensor\n",
    "import torch \n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "\n",
    "# Convert X_train, X_val, and X_test to torch tensors\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "#X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "x_valid = torch.tensor(x_valid, dtype=torch.float32)\n",
    "\n",
    "# Convert y_train, y_val, and y_test to torch tensors\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "#y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([725, 3, 160, 320])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([725, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://learn.microsoft.com/en-us/windows/ai/windows-ml/tutorials/pytorch-train-model\n",
    "How does a Neural Network work?\n",
    "\n",
    "1-Copy the following code into the PyTorchTraining.py file in Visual Studio to define the CCN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "# Define a convolution neural network\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(24)\n",
    "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(24)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(273504, 2)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr = 0.001)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        #print(input.shape)\n",
    "        output = F.relu(self.bn1(self.conv1(input)))      \n",
    "        output = F.relu(self.bn2(self.conv2(output)))     \n",
    "        output = self.pool(output)                        \n",
    "        output = F.relu(self.bn4(self.conv4(output)))     \n",
    "        output = F.relu(self.bn5(self.conv5(output)))     \n",
    "        output = self.flat(output)\n",
    "        output = self.fc1(output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_val, y_val, batch_size=32, epochs=50):\n",
    "\n",
    "      dataset = TensorDataset(X_train, y_train)\n",
    "      dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "      for epoch in range(epochs):\n",
    "          self.train()\n",
    "\n",
    "          cn_loss = 0\n",
    "\n",
    "          for batch_X, batch_y in dataloader:\n",
    "              self.optimizer.zero_grad()\n",
    "              outputs = self(batch_X)\n",
    "              loss = self.criterion(outputs, batch_y)\n",
    "              loss.backward()\n",
    "              cn_loss += loss.item()\n",
    "              self.optimizer.step()\n",
    "\n",
    "          cn_loss /= len(dataloader)\n",
    "\n",
    "          #self.scheduler.step()\n",
    "          self.eval()\n",
    "          with torch.no_grad():\n",
    "              val_outputs = self(X_val)\n",
    "              val_loss = self.criterion(val_outputs, y_val)\n",
    "\n",
    "          epoch_data = {\n",
    "              \"no\": epoch,\n",
    "              \"loss\": cn_loss,\n",
    "              \"val_loss\": val_loss.item()\n",
    "          }\n",
    "          #self.history.append(epoch_data)\n",
    "          print(f'Epoch [{epoch+1}/{epochs}], Loss: {cn_loss:.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# Instantiate a neural network model \n",
    "model = Network()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 778.5635, Val Loss: 40.4191\n",
      "Epoch [2/50], Loss: 19.6630, Val Loss: 21.3031\n",
      "Epoch [3/50], Loss: 3.1363, Val Loss: 2.2939\n",
      "Epoch [4/50], Loss: 1.0491, Val Loss: 1.3268\n",
      "Epoch [5/50], Loss: 0.5745, Val Loss: 0.5569\n",
      "Epoch [6/50], Loss: 0.4667, Val Loss: 0.3661\n",
      "Epoch [7/50], Loss: 0.3130, Val Loss: 0.3645\n",
      "Epoch [8/50], Loss: 0.2949, Val Loss: 0.3928\n",
      "Epoch [9/50], Loss: 0.1801, Val Loss: 0.2181\n",
      "Epoch [10/50], Loss: 0.1945, Val Loss: 0.2520\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/shiryezzat/AI/deep_learning_project/data/read.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, x_valid, y_valid)\n",
      "\u001b[1;32m/home/shiryezzat/AI/deep_learning_project/data/read.ipynb Cell 21\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X26sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(batch_X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X26sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(outputs, batch_y)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X26sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X26sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m cn_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X26sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Define a loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    " \n",
    "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Train the model on the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "# Function to save the model\n",
    "def saveModel():\n",
    "    path = \"./myFirstModel.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def testAccuracy():\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)\n",
    "\n",
    "\n",
    "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
    "def train(num_epochs):\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    # Define your execution device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "    # Convert model parameters and buffers to CPU or Cuda\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "            \n",
    "            # get the inputs\n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # predict classes using images from the training set\n",
    "            outputs = model(images)\n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Let's print statistics for every 1,000 images\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            if i % 1000 == 999:    \n",
    "                # print every 1000 (twice per epoch) \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 1000))\n",
    "                # zero the loss\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images\n",
    "        accuracy = testAccuracy()\n",
    "        print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
    "        \n",
    "        # we want to save the model if the accuracy is the best\n",
    "        if accuracy > best_accuracy:\n",
    "            saveModel()\n",
    "            best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Test the model on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to show the images\n",
    "def imageshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Function to test the model with a batch of images and show the labels predictions\n",
    "def testBatch():\n",
    "    # get batch of images from the test DataLoader  \n",
    "    images, labels = next(iter(test_loader))\n",
    "\n",
    "    # show all images as one image grid\n",
    "    imageshow(torchvision.utils.make_grid(images))\n",
    "   \n",
    "    # Show the real labels on the screen \n",
    "  \n",
    "  \n",
    "    # Let's see what if the model identifiers the  labels of those example\n",
    "    outputs = model(images)\n",
    "    \n",
    "    # We got the probability for every 10 labels. The highest (max) probability should be correct label\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    # Let's show the predicted labels on the screen to compare with the real ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Main Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cuda:0 device\n",
      "torch.Size([3, 160, 320])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected 4D input (got 3D input)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/shiryezzat/AI/deep_learning_project/data/read.ipynb Cell 25\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# Let's build our model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train(\u001b[39m5\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFinished Training\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# Test which classes performed well\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Let's load the model we just created and test the accuracy per label\u001b[39;00m\n",
      "\u001b[1;32m/home/shiryezzat/AI/deep_learning_project/data/read.ipynb Cell 25\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# predict classes using images from the training set\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(images)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# compute the loss based on model output and real labels\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs, labels)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/shiryezzat/AI/deep_learning_project/data/read.ipynb Cell 25\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     output \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(\u001b[39minput\u001b[39;49m)))      \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     output \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(output)))     \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shiryezzat/AI/deep_learning_project/data/read.ipynb#X30sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(output)                        \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:138\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 138\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_input_dim(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39m# exponential_average_factor is set to self.momentum\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[39m# (when it is available) only so that it gets updated\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[39m# in ONNX graph when this node is exported to ONNX.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:416\u001b[0m, in \u001b[0;36mBatchNorm2d._check_input_dim\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_input_dim\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    415\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[0;32m--> 416\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected 4D input (got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39mD input)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: expected 4D input (got 3D input)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Let's build our model\n",
    "    train(5)\n",
    "    print('Finished Training')\n",
    "\n",
    "    # Test which classes performed well\n",
    "  \n",
    "    \n",
    "    # Let's load the model we just created and test the accuracy per label\n",
    "    model = Network()\n",
    "    path = \"myFirstModel.pth\"\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    # Test with batch of images\n",
    "    testBatch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
